{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Lab6.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOuyF8y6BBlF4fdp3Rt/GRO"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"RC5IfekxKTNY"},"source":["!pip uninstall tensorflow"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tkGTEaRV-hQP"},"source":["!pip install tensorflow==1.15 # 1.15 버전 Tensorflow 설치"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"llvavOqm-suo"},"source":["# SoftMax Classification (Multinomial classification)"]},{"cell_type":"code","metadata":{"id":"7ZXFIdPy-p4G","executionInfo":{"status":"ok","timestamp":1609203173969,"user_tz":-540,"elapsed":2698,"user":{"displayName":"김상호","photoUrl":"","userId":"04350162671667855893"}}},"source":["import tensorflow as tf\r\n","tf.set_random_seed(777)  # for reproducibility\r\n","\r\n","x_data = [[1, 2, 1, 1],\r\n","          [2, 1, 3, 2],\r\n","          [3, 1, 3, 4],\r\n","          [4, 1, 5, 5],\r\n","          [1, 7, 5, 5],\r\n","          [1, 2, 5, 6],\r\n","          [1, 6, 6, 6],\r\n","          [1, 7, 7, 7]]\r\n","y_data = [[0, 0, 1],\r\n","          [0, 0, 1],\r\n","          [0, 0, 1],\r\n","          [0, 1, 0],\r\n","          [0, 1, 0],\r\n","          [0, 1, 0],\r\n","          [1, 0, 0],\r\n","          [1, 0, 0]]\r\n","\r\n","X = tf.placeholder(\"float\", [None, 4])\r\n","Y = tf.placeholder(\"float\", [None, 3])\r\n","nb_class = 3;\r\n","\r\n","W = tf.Variable(tf.random_normal([4, nb_class], name = \"weight\"))\r\n","b = tf.Variable(tf.random_normal([nb_class]), name = \"bias\")\r\n","\r\n","# softmax\r\n","hypothesis = tf.nn.softmax(tf.matmul(X, W) + b)"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"oyRskowk-uPx","executionInfo":{"status":"ok","timestamp":1609203175243,"user_tz":-540,"elapsed":820,"user":{"displayName":"김상호","photoUrl":"","userId":"04350162671667855893"}}},"source":["cost = tf.reduce_mean(-tf.reduce_sum(Y * tf.log(hypothesis), axis=1))\r\n","train = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gHwqMhNx-v5g","executionInfo":{"status":"ok","timestamp":1609203182171,"user_tz":-540,"elapsed":6545,"user":{"displayName":"김상호","photoUrl":"","userId":"04350162671667855893"}},"outputId":"30ee8bfe-7104-4075-f8cc-7156ae642c1b"},"source":["with tf.Session() as sess:\r\n","    sess.run(tf.global_variables_initializer())\r\n","\r\n","    for step in range(10001):\r\n","        cost_val, _ = sess.run([cost, train], feed_dict = {X:x_data, Y:y_data})\r\n","        if step % 1000 == 0:\r\n","            print(step, cost_val)\r\n","\r\n","    print('--------------')\r\n","    # Testing & One-hot encoding\r\n","    a = sess.run(hypothesis, feed_dict={X: [[1, 11, 7, 9]]})\r\n","    print(a, sess.run(tf.argmax(a, 1)))\r\n","\r\n","    print('--------------')\r\n","    b = sess.run(hypothesis, feed_dict = {X: [[1, 3, 4, 3]]})\r\n","    print(b, sess.run(tf.arg_max(b, 1)))\r\n","\r\n","    print('--------------')\r\n","    c = sess.run(hypothesis, feed_dict = {X: [[1, 1, 0, 1]]})\r\n","    print(c, sess.run(tf.arg_max(c, 1)))\r\n","\r\n","    print('--------------')\r\n","    all = sess.run(hypothesis, feed_dict = {X: [[1, 11, 7, 9], [1, 3, 4, 3], [1, 1, 0, 1]]})\r\n","    print(all, sess.run(tf.arg_max(all, 1)))"],"execution_count":5,"outputs":[{"output_type":"stream","text":["0 6.926112\n","1000 0.23280531\n","2000 0.15216155\n","3000 0.112435445\n","4000 0.08892067\n","5000 0.07343659\n","6000 0.06249354\n","7000 0.0543602\n","8000 0.048083052\n","9000 0.043094594\n","10000 0.039036863\n","--------------\n","[[4.6538315e-07 9.9999952e-01 3.5441222e-08]] [1]\n","--------------\n","[[9.974734e-01 2.451452e-03 7.510649e-05]] [0]\n","--------------\n","[[8.988214e-16 5.665233e-07 9.999994e-01]] [2]\n","--------------\n","[[4.6538227e-07 9.9999952e-01 3.5441289e-08]\n"," [9.9747342e-01 2.4514566e-03 7.5106625e-05]\n"," [8.9882139e-16 5.6652323e-07 9.9999940e-01]] [1 0 2]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"mtBY504s-yNL"},"source":["# Fency Softmax Classifier using zoo data\r\n","\r\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iunS5S3r-x8o","executionInfo":{"status":"ok","timestamp":1609203204504,"user_tz":-540,"elapsed":20194,"user":{"displayName":"김상호","photoUrl":"","userId":"04350162671667855893"}},"outputId":"ca30f452-6c3f-41ce-f845-e1cd3563a52e"},"source":["from google.colab import drive, files\r\n","drive.mount('/content/drive')"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"IwiDd7rc-1cR","executionInfo":{"status":"ok","timestamp":1609203207651,"user_tz":-540,"elapsed":1505,"user":{"displayName":"김상호","photoUrl":"","userId":"04350162671667855893"}}},"source":["import tensorflow as tf\r\n","import numpy as np\r\n","tf.set_random_seed(777)\r\n","\r\n","xy = np.loadtxt('/content/drive/My Drive/모두의 딥러닝/data-04-zoo.csv', delimiter = ',', dtype = np.float32)\r\n","x_data = xy[:, 0:-1]\r\n","y_data = xy[:, [-1]]"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"02vA0kfy-3OM","executionInfo":{"status":"ok","timestamp":1609203209006,"user_tz":-540,"elapsed":766,"user":{"displayName":"김상호","photoUrl":"","userId":"04350162671667855893"}},"outputId":"6d074027-456a-4564-e44d-812cce634512"},"source":["print(x_data.shape, y_data.shape)"],"execution_count":8,"outputs":[{"output_type":"stream","text":["(101, 16) (101, 1)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XrCqrRO--47G","executionInfo":{"status":"ok","timestamp":1609203210858,"user_tz":-540,"elapsed":1460,"user":{"displayName":"김상호","photoUrl":"","userId":"04350162671667855893"}},"outputId":"6127fe67-2964-45d6-8a52-72535f4e8b8c"},"source":["nb_class = 7\r\n","\r\n","X = tf.placeholder(tf.float32, [None, 16])\r\n","Y = tf.placeholder(tf.int32, [None, 1])\r\n","\r\n","# one-hot encoding을 하면 rank가 1 증가함 따라서 원래 형태로 바꾸어줘야됨\r\n","Y_one_hot = tf.one_hot(Y, nb_class) # one-hot encoding 실행\r\n","print(\"one_hot : \", Y_one_hot)\r\n","Y_one_hot = tf.reshape(Y_one_hot, [-1, nb_class]) # 형태 재구성\r\n","print(\"reshape one_hot : \", Y_one_hot)\r\n","\r\n","W = tf.Variable(tf.random_normal([16, nb_class]), name=\"weight\")\r\n","b = tf.Variable(tf.random_normal([nb_class]), name = \"bias\")\r\n","\r\n","logits = tf.matmul(X, W) + b\r\n","hypothesis = tf.nn.softmax(logits)\r\n","\r\n","# version 1\r\n","#cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels = Y_one_hot))\r\n","\r\n","# version 2\r\n","cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits, labels=tf.stop_gradient([Y_one_hot]))) #stop_gradient함수는 학습하는 부분을 나누어 학습하고자 할 때 사용한다.\r\n","train = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)\r\n","\r\n","prediction = tf.arg_max(hypothesis, 1) # 가설함수의 값에서 가장 큰 값을 얻음\r\n","correct_prediction = tf.equal(prediction, tf.arg_max(Y_one_hot, 1)) # 위에서 얻은 값과 실제 값이 같은지 확인 (1은 열을 기준으로 확인)\r\n","accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32)) # 앞서 얻은 모든 예측 값을 더해서 평균을 계산해 정확도를 계산"],"execution_count":9,"outputs":[{"output_type":"stream","text":["one_hot :  Tensor(\"one_hot:0\", shape=(?, 1, 7), dtype=float32)\n","reshape one_hot :  Tensor(\"Reshape:0\", shape=(?, 7), dtype=float32)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WE3RiJjO-6Ve","executionInfo":{"status":"ok","timestamp":1609203214450,"user_tz":-540,"elapsed":2646,"user":{"displayName":"김상호","photoUrl":"","userId":"04350162671667855893"}},"outputId":"cc2bc425-29db-4a69-b9b1-93f9c7eb5cfb"},"source":["with tf.Session() as sess:\r\n","    sess.run(tf.global_variables_initializer())\r\n","\r\n","    for step in range(2001):\r\n","        _, cost_val, acc_val = sess.run([train, cost, accuracy], feed_dict={X:x_data, Y:y_data})\r\n","        if step % 500 == 0:\r\n","            print(\"Step: {:5}\\tCost: {:.3f}\\tAcc: {:.2%}\".format(step, cost_val, acc_val))\r\n","\r\n","    pred = sess.run(prediction, feed_dict={X:x_data})\r\n","    for p, y in zip(pred, y_data.flatten()): # flatten함수는 n차원으로 이루어진 데이터를 직렬화한다.\r\n","        print(\"[{}] Prediction : {} True Y : {}\".format(p == int(y), p, int(y)))"],"execution_count":10,"outputs":[{"output_type":"stream","text":["Step:     0\tCost: 4.144\tAcc: 25.74%\n","Step:   500\tCost: 0.205\tAcc: 95.05%\n","Step:  1000\tCost: 0.112\tAcc: 99.01%\n","Step:  1500\tCost: 0.076\tAcc: 100.00%\n","Step:  2000\tCost: 0.058\tAcc: 100.00%\n","[True] Prediction : 0 True Y : 0\n","[True] Prediction : 0 True Y : 0\n","[True] Prediction : 3 True Y : 3\n","[True] Prediction : 0 True Y : 0\n","[True] Prediction : 0 True Y : 0\n","[True] Prediction : 0 True Y : 0\n","[True] Prediction : 0 True Y : 0\n","[True] Prediction : 3 True Y : 3\n","[True] Prediction : 3 True Y : 3\n","[True] Prediction : 0 True Y : 0\n","[True] Prediction : 0 True Y : 0\n","[True] Prediction : 1 True Y : 1\n","[True] Prediction : 3 True Y : 3\n","[True] Prediction : 6 True Y : 6\n","[True] Prediction : 6 True Y : 6\n","[True] Prediction : 6 True Y : 6\n","[True] Prediction : 1 True Y : 1\n","[True] Prediction : 0 True Y : 0\n","[True] Prediction : 3 True Y : 3\n","[True] Prediction : 0 True Y : 0\n","[True] Prediction : 1 True Y : 1\n","[True] Prediction : 1 True Y : 1\n","[True] Prediction : 0 True Y : 0\n","[True] Prediction : 1 True Y : 1\n","[True] Prediction : 5 True Y : 5\n","[True] Prediction : 4 True Y : 4\n","[True] Prediction : 4 True Y : 4\n","[True] Prediction : 0 True Y : 0\n","[True] Prediction : 0 True Y : 0\n","[True] Prediction : 0 True Y : 0\n","[True] Prediction : 5 True Y : 5\n","[True] Prediction : 0 True Y : 0\n","[True] Prediction : 0 True Y : 0\n","[True] Prediction : 1 True Y : 1\n","[True] Prediction : 3 True Y : 3\n","[True] Prediction : 0 True Y : 0\n","[True] Prediction : 0 True Y : 0\n","[True] Prediction : 1 True Y : 1\n","[True] Prediction : 3 True Y : 3\n","[True] Prediction : 5 True Y : 5\n","[True] Prediction : 5 True Y : 5\n","[True] Prediction : 1 True Y : 1\n","[True] Prediction : 5 True Y : 5\n","[True] Prediction : 1 True Y : 1\n","[True] Prediction : 0 True Y : 0\n","[True] Prediction : 0 True Y : 0\n","[True] Prediction : 6 True Y : 6\n","[True] Prediction : 0 True Y : 0\n","[True] Prediction : 0 True Y : 0\n","[True] Prediction : 0 True Y : 0\n","[True] Prediction : 0 True Y : 0\n","[True] Prediction : 5 True Y : 5\n","[True] Prediction : 4 True Y : 4\n","[True] Prediction : 6 True Y : 6\n","[True] Prediction : 0 True Y : 0\n","[True] Prediction : 0 True Y : 0\n","[True] Prediction : 1 True Y : 1\n","[True] Prediction : 1 True Y : 1\n","[True] Prediction : 1 True Y : 1\n","[True] Prediction : 1 True Y : 1\n","[True] Prediction : 3 True Y : 3\n","[True] Prediction : 3 True Y : 3\n","[True] Prediction : 2 True Y : 2\n","[True] Prediction : 0 True Y : 0\n","[True] Prediction : 0 True Y : 0\n","[True] Prediction : 0 True Y : 0\n","[True] Prediction : 0 True Y : 0\n","[True] Prediction : 0 True Y : 0\n","[True] Prediction : 0 True Y : 0\n","[True] Prediction : 0 True Y : 0\n","[True] Prediction : 0 True Y : 0\n","[True] Prediction : 1 True Y : 1\n","[True] Prediction : 6 True Y : 6\n","[True] Prediction : 3 True Y : 3\n","[True] Prediction : 0 True Y : 0\n","[True] Prediction : 0 True Y : 0\n","[True] Prediction : 2 True Y : 2\n","[True] Prediction : 6 True Y : 6\n","[True] Prediction : 1 True Y : 1\n","[True] Prediction : 1 True Y : 1\n","[True] Prediction : 2 True Y : 2\n","[True] Prediction : 6 True Y : 6\n","[True] Prediction : 3 True Y : 3\n","[True] Prediction : 1 True Y : 1\n","[True] Prediction : 0 True Y : 0\n","[True] Prediction : 6 True Y : 6\n","[True] Prediction : 3 True Y : 3\n","[True] Prediction : 1 True Y : 1\n","[True] Prediction : 5 True Y : 5\n","[True] Prediction : 4 True Y : 4\n","[True] Prediction : 2 True Y : 2\n","[True] Prediction : 2 True Y : 2\n","[True] Prediction : 3 True Y : 3\n","[True] Prediction : 0 True Y : 0\n","[True] Prediction : 0 True Y : 0\n","[True] Prediction : 1 True Y : 1\n","[True] Prediction : 0 True Y : 0\n","[True] Prediction : 5 True Y : 5\n","[True] Prediction : 0 True Y : 0\n","[True] Prediction : 6 True Y : 6\n","[True] Prediction : 1 True Y : 1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"wNJsQMyw_F3f"},"source":[""],"execution_count":null,"outputs":[]}]}